package nornicdb

import (
	"context"
	"testing"
	"time"

	featureflags "github.com/orneryd/nornicdb/pkg/config"
	"github.com/orneryd/nornicdb/pkg/storage"
	"github.com/stretchr/testify/require"
)

func TestSearchServices_PerDatabaseIsolation_EventRouting(t *testing.T) {
	cfg := DefaultConfig()
	cfg.EmbeddingDimensions = 3
	db, err := Open("", cfg)
	require.NoError(t, err)
	t.Cleanup(func() { _ = db.Close() })

	ctx, cancel := context.WithTimeout(context.Background(), 5*time.Second)
	defer cancel()

	// Create and index a node in the default database (nornic).
	alpha := &storage.Node{
		ID:     storage.NodeID("alpha"),
		Labels: []string{"Doc"},
		Properties: map[string]any{
			"content": "hello alpha",
		},
		ChunkEmbeddings: [][]float32{{0.1, 0.2, 0.3}},
	}
	_, err = db.storage.CreateNode(alpha)
	require.NoError(t, err)
	db.indexNodeFromEvent(&storage.Node{
		ID:             storage.NodeID("nornic:alpha"),
		Labels:         alpha.Labels,
		Properties:     alpha.Properties,
		ChunkEmbeddings: alpha.ChunkEmbeddings,
	})

	// Create and index a node in another database.
	db2Storage := storage.NewNamespacedEngine(db.baseStorage, "db2")
	beta := &storage.Node{
		ID:     storage.NodeID("beta"),
		Labels: []string{"Doc"},
		Properties: map[string]any{
			"content": "world beta",
		},
		ChunkEmbeddings: [][]float32{{0.4, 0.5, 0.6}},
	}
	_, err = db2Storage.CreateNode(beta)
	require.NoError(t, err)
	db.indexNodeFromEvent(&storage.Node{
		ID:             storage.NodeID("db2:beta"),
		Labels:         beta.Labels,
		Properties:     beta.Properties,
		ChunkEmbeddings: beta.ChunkEmbeddings,
	})

	// Default DB service should only contain default DB embedding.
	defaultSvc, err := db.GetOrCreateSearchService(db.defaultDatabaseName(), db.storage)
	require.NoError(t, err)
	require.Equal(t, 1, defaultSvc.EmbeddingCount())

	// db2 service should exist and contain only db2 embedding.
	db2Svc, err := db.GetOrCreateSearchService("db2", nil)
	require.NoError(t, err)
	require.Equal(t, 1, db2Svc.EmbeddingCount())

	// Verify text-only search does not cross-contaminate.
	// Default DB should find alpha, not beta.
	resp, err := defaultSvc.Search(ctx, "world", nil, nil)
	require.NoError(t, err)
	require.Len(t, resp.Results, 0)

	resp, err = defaultSvc.Search(ctx, "hello", nil, nil)
	require.NoError(t, err)
	require.GreaterOrEqual(t, len(resp.Results), 1)

	// db2 should find beta, not alpha.
	resp, err = db2Svc.Search(ctx, "hello", nil, nil)
	require.NoError(t, err)
	require.Len(t, resp.Results, 0)

	resp, err = db2Svc.Search(ctx, "world", nil, nil)
	require.NoError(t, err)
	require.GreaterOrEqual(t, len(resp.Results), 1)
}

func TestSearchServices_ResetDropsCache(t *testing.T) {
	cfg := DefaultConfig()
	cfg.EmbeddingDimensions = 3
	db, err := Open("", cfg)
	require.NoError(t, err)
	t.Cleanup(func() { _ = db.Close() })

	_, err = db.GetOrCreateSearchService("db2", nil)
	require.NoError(t, err)

	db.searchServicesMu.RLock()
	_, exists := db.searchServices["db2"]
	db.searchServicesMu.RUnlock()
	require.True(t, exists)

	db.ResetSearchService("db2")

	db.searchServicesMu.RLock()
	_, exists = db.searchServices["db2"]
	db.searchServicesMu.RUnlock()
	require.False(t, exists)
}

func TestSearchServices_ClusteringRunnerInitializesKnownNamespaces(t *testing.T) {
	cleanup := featureflags.WithGPUClusteringEnabled()
	t.Cleanup(cleanup)

	cfg := DefaultConfig()
	cfg.EmbeddingDimensions = 3
	db, err := Open("", cfg)
	require.NoError(t, err)
	t.Cleanup(func() { _ = db.Close() })

	// Create a node in a second database without touching the search service cache.
	db2Storage := storage.NewNamespacedEngine(db.baseStorage, "db2")
	_, err = db2Storage.CreateNode(&storage.Node{
		ID:     storage.NodeID("beta"),
		Labels: []string{"Doc"},
		Properties: map[string]any{
			"content": "world beta",
		},
		ChunkEmbeddings: [][]float32{{0.4, 0.5, 0.6}},
	})
	require.NoError(t, err)

	// The clustering runner should discover db2 and initialize a search service for it.
	db.runClusteringOnceAllDatabases(context.Background())

	db.searchServicesMu.RLock()
	_, db2Exists := db.searchServices["db2"]
	_, systemExists := db.searchServices["system"]
	db.searchServicesMu.RUnlock()

	require.True(t, db2Exists)
	require.False(t, systemExists)
}

func TestSearchServices_ClusteringFlagUpgradesCachedService(t *testing.T) {
	cleanup := featureflags.WithGPUClusteringDisabled()
	t.Cleanup(cleanup)

	cfg := DefaultConfig()
	cfg.EmbeddingDimensions = 3
	db, err := Open("", cfg)
	require.NoError(t, err)
	t.Cleanup(func() { _ = db.Close() })

	// Create service while clustering is disabled.
	svc, err := db.GetOrCreateSearchService(db.defaultDatabaseName(), db.storage)
	require.NoError(t, err)
	require.False(t, svc.IsClusteringEnabled())

	// Enable clustering and run the clustering runner; it should upgrade the cached service.
	enable := featureflags.WithGPUClusteringEnabled()
	t.Cleanup(enable)

	db.runClusteringOnceAllDatabases(context.Background())

	svc, err = db.GetOrCreateSearchService(db.defaultDatabaseName(), db.storage)
	require.NoError(t, err)
	require.True(t, svc.IsClusteringEnabled())
}

func TestSearchServices_SkipsQdrantNamespaceNodes(t *testing.T) {
	cfg := DefaultConfig()
	cfg.EmbeddingDimensions = 3
	db, err := Open("", cfg)
	require.NoError(t, err)
	t.Cleanup(func() { _ = db.Close() })

	svc, err := db.GetOrCreateSearchService(db.defaultDatabaseName(), db.storage)
	require.NoError(t, err)

	before := svc.EmbeddingCount()
	db.indexNodeFromEvent(&storage.Node{
		ID: storage.NodeID("nornic:qdrant:bench_col:1"),
		NamedEmbeddings: map[string][]float32{
			"default": {1, 0, 0},
		},
	})
	after := svc.EmbeddingCount()
	require.Equal(t, before, after)
}

// TestRunClusteringOnceAllDatabases_RespectsContextCancellation verifies that
// runClusteringOnceAllDatabases returns promptly when the context is cancelled
// (e.g. on server shutdown). The goroutine must exit so Close() can complete.
func TestRunClusteringOnceAllDatabases_RespectsContextCancellation(t *testing.T) {
	cleanup := featureflags.WithGPUClusteringEnabled()
	t.Cleanup(cleanup)

	cfg := DefaultConfig()
	cfg.EmbeddingDimensions = 3
	db, err := Open("", cfg)
	require.NoError(t, err)
	t.Cleanup(func() { _ = db.Close() })

	ctx, cancel := context.WithCancel(context.Background())
	cancel() // Cancel immediately so runClusteringOnceAllDatabases exits right away.

	done := make(chan struct{})
	go func() {
		defer close(done)
		db.runClusteringOnceAllDatabases(ctx)
	}()

	select {
	case <-done:
		// Goroutine exited; cancellation was respected.
	case <-time.After(2 * time.Second):
		t.Fatal("runClusteringOnceAllDatabases did not return after context cancellation within 2s")
	}
}

// TestTriggerSearchClustering_DoesNotPanic verifies TriggerSearchClustering
// runs without panicking when buildCtx is set (normal Open path) and when
// clustering is disabled (returns early). Also ensures nil buildCtx is handled
// defensively in code paths that may call TriggerSearchClustering.
func TestTriggerSearchClustering_DoesNotPanic(t *testing.T) {
	t.Run("clustering_disabled_returns_early", func(t *testing.T) {
		cleanup := featureflags.WithGPUClusteringDisabled()
		t.Cleanup(cleanup)

		cfg := DefaultConfig()
		cfg.EmbeddingDimensions = 3
		db, err := Open("", cfg)
		require.NoError(t, err)
		t.Cleanup(func() { _ = db.Close() })

		err = db.TriggerSearchClustering()
		require.NoError(t, err)
	})

	t.Run("clustering_enabled_uses_buildCtx", func(t *testing.T) {
		cleanup := featureflags.WithGPUClusteringEnabled()
		t.Cleanup(cleanup)

		cfg := DefaultConfig()
		cfg.EmbeddingDimensions = 3
		db, err := Open("", cfg)
		require.NoError(t, err)
		t.Cleanup(func() { _ = db.Close() })

		require.NotNil(t, db.buildCtx, "Open() should set buildCtx so clustering can be cancelled on Close()")
		err = db.TriggerSearchClustering()
		require.NoError(t, err)
	})
}
